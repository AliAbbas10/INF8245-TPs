{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3c1916",
   "metadata": {},
   "source": [
    "**Sections:**\n",
    "1. **Pre-processing** : Data loading and exploration\n",
    "2. **Algorithms and Optimization** : Model training and comparison\n",
    "3. **Submissions** : Model selection and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752598a",
   "metadata": {},
   "source": [
    "## 1. Pre-processing\n",
    "\n",
    "Loading and analyzing the dataset\n",
    "\n",
    "### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f97806",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('data/train.npz')\n",
    "test = np.load('data/test.npz')\n",
    "\n",
    "X_train = train['X_train']\n",
    "y_train = train['y_train']\n",
    "train_ids = train['ids']\n",
    "\n",
    "X_test = test['X_test']\n",
    "test_ids = test['ids']\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]:,} samples x {X_train.shape[1]:,} features\")\n",
    "print(f\"Test: {X_test.shape[0]:,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a2d46",
   "metadata": {},
   "source": [
    "### 1.2 Data Exploration\n",
    "\n",
    "Analyzing class distribution and dataset characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train.shape\n",
    "n_susceptible = np.sum(y_train == 0)\n",
    "n_resistant = np.sum(y_train == 1)\n",
    "imbalance_ratio = n_susceptible / n_resistant\n",
    "\n",
    "non_zero = np.count_nonzero(X_train)\n",
    "total_entries = n_samples * n_features\n",
    "sparsity = 100 * (1 - non_zero / total_entries)\n",
    "\n",
    "print(f\"Samples: {n_samples:,} , Features: {n_features:,}\")\n",
    "print(f\"Class distribution: {n_susceptible:,} susceptible ({100*n_susceptible/n_samples:.1f}%), {n_resistant:,} resistant ({100*n_resistant/n_samples:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73049e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "class_labels = ['Susceptible', 'Resistant']\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "bars = plt.bar(class_labels, class_counts.values, color=['blue', 'red'], alpha=0.5)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.title('Class Distribution', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, class_counts.values)):\n",
    "    percentage = 100 * count / len(y_train)\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20, \n",
    "             f'{count:,}\\n({percentage:.1f}%)', ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68088f",
   "metadata": {},
   "source": [
    "### 1.3 Feature Selection\n",
    "\n",
    "Testing different feature counts and applying variance threshold and chi-square selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_values = [5000, 10000, 15000, 20000, 30000]\n",
    "\n",
    "variance_threshold = VarianceThreshold(threshold=0.01)\n",
    "X_train_var = variance_threshold.fit_transform(X_train)\n",
    "X_test_var = variance_threshold.transform(X_test)\n",
    "\n",
    "print(f\"After variance threshold: {X_train_var.shape[1]:,} features\\n\")\n",
    "\n",
    "results = []\n",
    "for k in k_values:\n",
    "    if k > X_train_var.shape[1]:\n",
    "        continue\n",
    "    \n",
    "    selector = SelectKBest(chi2, k=k)\n",
    "    X_train_k = selector.fit_transform(X_train_var, y_train)\n",
    "    X_test_k = selector.transform(X_test_var)\n",
    "    \n",
    "    # test with Logistic Regression\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42, n_jobs=-1)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(lr, X_train_k, y_train, cv=cv, scoring=make_scorer(f1_score, average='macro'), n_jobs=-1)\n",
    "    \n",
    "    results.append({'k': k, 'cv_f1': scores.mean(), 'cv_std': scores.std()})\n",
    "    print(f\"K={k:6,}: CV F1 = {scores.mean():.4f} and std deviation of {scores.std():.4f}\")\n",
    "\n",
    "best_result = max(results, key=lambda x: x['cv_f1'])\n",
    "K_FEATURES = best_result['k']\n",
    "print(f\"\\nBest K: {K_FEATURES:,} features (CV F1 = {best_result['cv_f1']:.4f})\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('feature_selection_results.csv', index=False)\n",
    "print(f\"Feature selection results saved to feature_selection_results.csv\")\n",
    "\n",
    "# Apply best K\n",
    "selector = SelectKBest(chi2, k=K_FEATURES)\n",
    "X_train_selected = selector.fit_transform(X_train_var, y_train)\n",
    "X_test_selected = selector.transform(X_test_var)\n",
    "\n",
    "print(f\"\\nFinal feature selection: {X_train_selected.shape[1]:,} features\")\n",
    "# 30000 is best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c00964",
   "metadata": {},
   "source": [
    "## 2. Training Algorithms\n",
    "\n",
    "Training classification models with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31fd02",
   "metadata": {},
   "source": [
    "### 2.1 Grid Search Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [10, 15, 20, 25, None],\n",
    "    'min_samples_split': [5, 10, 15, 20],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'scale_pos_weight': [scale_pos_weight]\n",
    "}\n",
    "\n",
    "print(f\"Using 5-fold cross-validation\")\n",
    "print(f\"Class imbalance ratio: {scale_pos_weight:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ac883",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_params,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Best RF: F1 = {rf_grid.best_score_:.4f}, Params = {rf_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a496379",
   "metadata": {},
   "source": [
    "### 2.3 Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65aec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42, n_jobs=1),\n",
    "    lr_params,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Best LR: F1 = {lr_grid.best_score_:.4f}, Params = {lr_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786720d",
   "metadata": {},
   "source": [
    "### 2.4 SVM Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f734e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(class_weight='balanced', random_state=42, cache_size=1000),\n",
    "    svm_params,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best SVM: F1 = {svm_grid.best_score_:.4f}, Params = {svm_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf5ce3",
   "metadata": {},
   "source": [
    "### 2.5 XGBoost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0257969",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = GridSearchCV(\n",
    "    xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method='hist'\n",
    "    ),\n",
    "    xgb_params,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Best XGBoost: F1 = {xgb_grid.best_score_:.4f}, Params = {xgb_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9582d",
   "metadata": {},
   "source": [
    "### 2.6 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = pd.DataFrame(rf_grid.cv_results_)\n",
    "lr_results = pd.DataFrame(lr_grid.cv_results_)\n",
    "svm_results = pd.DataFrame(svm_grid.cv_results_)\n",
    "xgb_results = pd.DataFrame(xgb_grid.cv_results_)\n",
    "\n",
    "rf_all = rf_results.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "lr_all = lr_results.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "svm_all = svm_results.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "xgb_all = xgb_results.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, row in rf_all.iterrows():\n",
    "    all_results.append({\n",
    "        'Model': 'RandomForest',\n",
    "        'Rank': int(row['rank_test_score']),\n",
    "        'CV_F1': row['mean_test_score'],\n",
    "        'CV_Std': row['std_test_score'],\n",
    "        'Config': str(row['params'])\n",
    "    })\n",
    "\n",
    "for idx, row in lr_all.iterrows():\n",
    "    all_results.append({\n",
    "        'Model': 'LogisticRegression',\n",
    "        'Rank': int(row['rank_test_score']),\n",
    "        'CV_F1': row['mean_test_score'],\n",
    "        'CV_Std': row['std_test_score'],\n",
    "        'Config': str(row['params'])\n",
    "    })\n",
    "\n",
    "for idx, row in svm_all.iterrows():\n",
    "    all_results.append({\n",
    "        'Model': 'SVM',\n",
    "        'Rank': int(row['rank_test_score']),\n",
    "        'CV_F1': row['mean_test_score'],\n",
    "        'CV_Std': row['std_test_score'],\n",
    "        'Config': str(row['params'])\n",
    "    })\n",
    "\n",
    "for idx, row in xgb_all.iterrows():\n",
    "    all_results.append({\n",
    "        'Model': 'XGBoost',\n",
    "        'Rank': int(row['rank_test_score']),\n",
    "        'CV_F1': row['mean_test_score'],\n",
    "        'CV_Std': row['std_test_score'],\n",
    "        'Config': str(row['params'])\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values('CV_F1', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Configurations:\")\n",
    "print(results_df.head(15).to_string(index=False))\n",
    "\n",
    "best = results_df.iloc[0]\n",
    "print(f\"\\nBest Model: {best['Model']} CV F1 = {best['CV_F1']:.4f}\")\n",
    "\n",
    "results_df.to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd164ee2",
   "metadata": {},
   "source": [
    "### 2.7 Results\n",
    "\n",
    "Visualizing model performance and hyperparameter impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406aac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_scores = {\n",
    "    'Random Forest': rf_grid.best_score_,\n",
    "    'Logistic Regression': lr_grid.best_score_,\n",
    "    'SVM': svm_grid.best_score_,\n",
    "    'XGBoost': xgb_grid.best_score_\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "models = list(best_scores.keys())\n",
    "scores = list(best_scores.values())\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "\n",
    "bars = ax.bar(models, scores, color=colors, alpha=0.5)\n",
    "ax.set_ylabel('F1 Score', fontsize=12)\n",
    "ax.set_title('Model Performance Comparison', fontsize=12)\n",
    "ax.set_ylim(min(scores) - 0.01, max(scores) + 0.01)\n",
    "ax.grid(axis='y', alpha=0.5)\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{score:.4f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best Model: {max(best_scores, key=best_scores.get)} (F1 = {max(best_scores.values()):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\n",
    "# Random Forest: n_estimators\n",
    "rf_params_analysis = []\n",
    "for idx, row in rf_results.iterrows():\n",
    "    params = row['params']\n",
    "    rf_params_analysis.append({\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "rf_df = pd.DataFrame(rf_params_analysis)\n",
    "rf_grouped = rf_df.groupby('n_estimators')['score'].mean().sort_index()\n",
    "\n",
    "axes[0, 0].plot(rf_grouped.index, rf_grouped.values, marker='s', linewidth=2, markersize=8, color='blue', alpha=0.5)\n",
    "axes[0, 0].set_xlabel('Number of Estimators', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[0, 0].set_title('Random Forest: n_estimators', fontsize=12)\n",
    "axes[0, 0].grid(alpha=0.5)\n",
    "\n",
    "# Random Forest: max_depth\n",
    "rf_depth_analysis = []\n",
    "for idx, row in rf_results.iterrows():\n",
    "    params = row['params']\n",
    "    depth = params['max_depth'] if params['max_depth'] is not None else 100\n",
    "    rf_depth_analysis.append({\n",
    "        'max_depth': depth,\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "rf_depth_df = pd.DataFrame(rf_depth_analysis)\n",
    "rf_depth_grouped = rf_depth_df.groupby('max_depth')['score'].mean().sort_index()\n",
    "\n",
    "axes[0, 1].plot(rf_depth_grouped.index, rf_depth_grouped.values, marker='^', linewidth=2, markersize=8, color='blue', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Max Depth', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[0, 1].set_title('Random Forest: max_depth', fontsize=12)\n",
    "axes[0, 1].grid(alpha=0.5)\n",
    "\n",
    "# Random Forest: min_samples_split\n",
    "rf_split_analysis = []\n",
    "for idx, row in rf_results.iterrows():\n",
    "    params = row['params']\n",
    "    rf_split_analysis.append({\n",
    "        'min_samples_split': params['min_samples_split'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "rf_split_df = pd.DataFrame(rf_split_analysis)\n",
    "rf_split_grouped = rf_split_df.groupby('min_samples_split')['score'].mean().sort_index()\n",
    "\n",
    "axes[0, 2].plot(rf_split_grouped.index, rf_split_grouped.values, marker='D', linewidth=2, markersize=8, color='blue', alpha=0.5)\n",
    "axes[0, 2].set_xlabel('Min Samples Split', fontsize=12)\n",
    "axes[0, 2].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[0, 2].set_title('Random Forest: min_samples_split', fontsize=12)\n",
    "axes[0, 2].grid(alpha=0.5)\n",
    "\n",
    "# XGBoost: learning_rate\n",
    "xgb_lr_analysis = []\n",
    "for idx, row in xgb_results.iterrows():\n",
    "    params = row['params']\n",
    "    xgb_lr_analysis.append({\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "xgb_lr_df = pd.DataFrame(xgb_lr_analysis)\n",
    "xgb_lr_grouped = xgb_lr_df.groupby('learning_rate')['score'].mean().sort_index()\n",
    "\n",
    "axes[0, 3].plot(xgb_lr_grouped.index, xgb_lr_grouped.values, marker='o', linewidth=2, markersize=8, color='orange', alpha=0.5)\n",
    "axes[0, 3].set_xlabel('Learning Rate', fontsize=12)\n",
    "axes[0, 3].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[0, 3].set_title('XGBoost: learning_rate', fontsize=12)\n",
    "axes[0, 3].grid(alpha=0.5)\n",
    "\n",
    "# XGBoost: max_depth\n",
    "xgb_depth_analysis = []\n",
    "for idx, row in xgb_results.iterrows():\n",
    "    params = row['params']\n",
    "    xgb_depth_analysis.append({\n",
    "        'max_depth': params['max_depth'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "xgb_depth_df = pd.DataFrame(xgb_depth_analysis)\n",
    "xgb_depth_grouped = xgb_depth_df.groupby('max_depth')['score'].mean().sort_index()\n",
    "\n",
    "axes[1, 0].plot(xgb_depth_grouped.index, xgb_depth_grouped.values, marker='*', linewidth=2, markersize=10, color='orange', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Max Depth', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[1, 0].set_title('XGBoost: max_depth', fontsize=12)\n",
    "axes[1, 0].grid(alpha=0.5)\n",
    "\n",
    "# XGBoost: n_estimators\n",
    "xgb_nest_analysis = []\n",
    "for idx, row in xgb_results.iterrows():\n",
    "    params = row['params']\n",
    "    xgb_nest_analysis.append({\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "xgb_nest_df = pd.DataFrame(xgb_nest_analysis)\n",
    "xgb_nest_grouped = xgb_nest_df.groupby('n_estimators')['score'].mean().sort_index()\n",
    "\n",
    "axes[1, 1].plot(xgb_nest_grouped.index, xgb_nest_grouped.values, marker='p', linewidth=2, markersize=8, color='orange', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Number of Estimators', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[1, 1].set_title('XGBoost: n_estimators', fontsize=12)\n",
    "axes[1, 1].grid(alpha=0.5)\n",
    "\n",
    "# XGBoost: subsample\n",
    "xgb_sub_analysis = []\n",
    "for idx, row in xgb_results.iterrows():\n",
    "    params = row['params']\n",
    "    xgb_sub_analysis.append({\n",
    "        'subsample': params['subsample'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "xgb_sub_df = pd.DataFrame(xgb_sub_analysis)\n",
    "xgb_sub_grouped = xgb_sub_df.groupby('subsample')['score'].mean().sort_index()\n",
    "\n",
    "axes[1, 2].plot(xgb_sub_grouped.index, xgb_sub_grouped.values, marker='h', linewidth=2, markersize=8, color='orange', alpha=0.5)\n",
    "axes[1, 2].set_xlabel('Subsample', fontsize=12)\n",
    "axes[1, 2].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[1, 2].set_title('XGBoost: subsample', fontsize=12)\n",
    "axes[1, 2].grid(alpha=0.5)\n",
    "\n",
    "# Logistic Regression: C parameter\n",
    "lr_c_analysis = []\n",
    "for idx, row in lr_results.iterrows():\n",
    "    params = row['params']\n",
    "    lr_c_analysis.append({\n",
    "        'C': params['C'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "lr_c_df = pd.DataFrame(lr_c_analysis)\n",
    "lr_c_grouped = lr_c_df.groupby('C')['score'].mean().sort_index()\n",
    "\n",
    "axes[1, 3].plot(lr_c_grouped.index, lr_c_grouped.values, marker='P', linewidth=2, markersize=8, color='red', alpha=0.5)\n",
    "axes[1, 3].set_xlabel('C', fontsize=12)\n",
    "axes[1, 3].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[1, 3].set_title('Logistic Regression: C', fontsize=12)\n",
    "axes[1, 3].set_xscale('log')\n",
    "axes[1, 3].grid(alpha=0.5)\n",
    "\n",
    "# SVM: kernel\n",
    "svm_kernel_analysis = []\n",
    "for idx, row in svm_results.iterrows():\n",
    "    params = row['params']\n",
    "    svm_kernel_analysis.append({\n",
    "        'kernel': params['kernel'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "svm_kernel_df = pd.DataFrame(svm_kernel_analysis)\n",
    "svm_kernel_grouped = svm_kernel_df.groupby('kernel')['score'].mean()\n",
    "\n",
    "axes[2, 0].bar(svm_kernel_grouped.index, svm_kernel_grouped.values, color=['green', 'lightgreen'], alpha=0.5)\n",
    "axes[2, 0].set_xlabel('Kernel Type', fontsize=12)\n",
    "axes[2, 0].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[2, 0].set_title('SVM: kernel', fontsize=12)\n",
    "axes[2, 0].grid(axis='y', alpha=0.5)\n",
    "\n",
    "for i, (kernel, score) in enumerate(svm_kernel_grouped.items()):\n",
    "    axes[2, 0].text(i, score, f'{score:.4f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# SVM: C parameter\n",
    "svm_c_analysis = []\n",
    "for idx, row in svm_results.iterrows():\n",
    "    params = row['params']\n",
    "    svm_c_analysis.append({\n",
    "        'C': params['C'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "svm_c_df = pd.DataFrame(svm_c_analysis)\n",
    "svm_c_grouped = svm_c_df.groupby('C')['score'].mean().sort_index()\n",
    "\n",
    "axes[2, 1].plot(svm_c_grouped.index, svm_c_grouped.values, marker='X', linewidth=2, markersize=8, color='green', alpha=0.5)\n",
    "axes[2, 1].set_xlabel('C', fontsize=12)\n",
    "axes[2, 1].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[2, 1].set_title('SVM: C', fontsize=12)\n",
    "axes[2, 1].set_xscale('log')\n",
    "axes[2, 1].grid(alpha=0.5)\n",
    "\n",
    "# SVM: gamma\n",
    "svm_gamma_analysis = []\n",
    "for idx, row in svm_results.iterrows():\n",
    "    params = row['params']\n",
    "    svm_gamma_analysis.append({\n",
    "        'gamma': params['gamma'],\n",
    "        'score': row['mean_test_score']\n",
    "    })\n",
    "svm_gamma_df = pd.DataFrame(svm_gamma_analysis)\n",
    "svm_gamma_grouped = svm_gamma_df.groupby('gamma')['score'].mean()\n",
    "\n",
    "axes[2, 2].bar(svm_gamma_grouped.index, svm_gamma_grouped.values, color=['green', 'darkgreen'], alpha=0.5)\n",
    "axes[2, 2].set_xlabel('Gamma', fontsize=12)\n",
    "axes[2, 2].set_ylabel('Mean F1 Score', fontsize=12)\n",
    "axes[2, 2].set_title('SVM: gamma', fontsize=12)\n",
    "axes[2, 2].grid(axis='y', alpha=0.5)\n",
    "\n",
    "for i, (gamma, score) in enumerate(svm_gamma_grouped.items()):\n",
    "    axes[2, 2].text(i, score, f'{score:.4f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "axes[2, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hyperparameter_analysis.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7359fa",
   "metadata": {},
   "source": [
    "## 3. Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef41c7",
   "metadata": {},
   "source": [
    "### 3.1 Random Forest Submission\n",
    "\n",
    "Generate submission using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    **rf_grid.best_params_,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_selected, y_train)\n",
    "y_test_pred_rf = rf.predict(X_test_selected)\n",
    "\n",
    "submission_rf = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred_rf\n",
    "})\n",
    "\n",
    "submission_rf.to_csv('rf_submission.csv', index=False)\n",
    "print(f\"Predicted resistant: {np.sum(y_test_pred_rf == 1)} ({100*np.sum(y_test_pred_rf == 1)/len(y_test_pred_rf):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc35bafa",
   "metadata": {},
   "source": [
    "### 3.2 Logistic Regression Submission\n",
    "\n",
    "Generate submission using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00453f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    **lr_grid.best_params_,\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr.fit(X_train_selected, y_train)\n",
    "y_test_pred_lr = lr.predict(X_test_selected)\n",
    "\n",
    "submission_lr = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred_lr\n",
    "})\n",
    "\n",
    "submission_lr.to_csv('lr_submission.csv', index=False)\n",
    "print(f\"Predicted resistant: {np.sum(y_test_pred_lr == 1)} ({100*np.sum(y_test_pred_lr == 1)/len(y_test_pred_lr):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfbe9f",
   "metadata": {},
   "source": [
    "### 3.3 SVM Submission\n",
    "\n",
    "Generate submission using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_best = SVC(\n",
    "    **svm_grid.best_params_,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    cache_size=1000\n",
    ")\n",
    "\n",
    "svm_best.fit(X_train_scaled, y_train)\n",
    "y_test_pred_svm = svm_best.predict(X_test_scaled)\n",
    "\n",
    "submission_svm_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred_svm\n",
    "})\n",
    "\n",
    "submission_svm_df.to_csv('svm_rbf_submission.csv', index=False)\n",
    "print(f\"Predicted resistant: {np.sum(y_test_pred_svm == 1)} ({100*np.sum(y_test_pred_svm == 1)/len(y_test_pred_svm):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33492c03",
   "metadata": {},
   "source": [
    "### 3.4 XGBoost Submission\n",
    "\n",
    "Generate submission using best XGBoost configuration from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee34fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgb.XGBClassifier(\n",
    "    **xgb_grid.best_params_,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "xgb_best.fit(X_train_selected, y_train)\n",
    "y_test_pred_xgb = xgb_best.predict(X_test_selected)\n",
    "\n",
    "submission_xgb_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred_xgb\n",
    "})\n",
    "\n",
    "submission_xgb_df.to_csv('xgboost_submission.csv', index=False)\n",
    "print(f\"Predicted resistant: {np.sum(y_test_pred_xgb == 1)} ({100*np.sum(y_test_pred_xgb == 1)/len(y_test_pred_xgb):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfecc87",
   "metadata": {},
   "source": [
    "### 3.5 Best Kaggle Submission\n",
    "\n",
    "Best performing XGBoost configuration (CV F1 = 0.8291)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26847fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_kaggle = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=10,\n",
    "    n_estimators=300,\n",
    "    scale_pos_weight=6.102564102564102,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "xgb_best_kaggle.fit(X_train_selected, y_train)\n",
    "y_test_pred_best_kaggle = xgb_best_kaggle.predict(X_test_selected)\n",
    "\n",
    "submission_best_kaggle = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred_best_kaggle\n",
    "})\n",
    "\n",
    "submission_best_kaggle.to_csv('best_kaggle_submission.csv', index=False)\n",
    "print(f\"Predicted resistant: {np.sum(y_test_pred_best_kaggle == 1)} ({100*np.sum(y_test_pred_best_kaggle == 1)/len(y_test_pred_best_kaggle):.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
