{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3c1916",
   "metadata": {},
   "source": [
    "**Structure:**\n",
    "1. **Pre-processing** - Data loading and exploration\n",
    "2. **Feature Selection** - Dimensionality reduction\n",
    "3. **Validation** - Cross-validation setup\n",
    "4. **Algorithms** - Model training and comparison\n",
    "5. **Optimization** - Model selection and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752598a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Pre-processing\n",
    "\n",
    "Load and analyze the dataset to understand characteristics and challenges\n",
    "\n",
    "### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f97806",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('data/train.npz')\n",
    "test = np.load('data/test.npz')\n",
    "\n",
    "X_train = train['X_train']\n",
    "y_train = train['y_train']\n",
    "train_ids = train['ids']\n",
    "\n",
    "X_test = test['X_test']\n",
    "test_ids = test['ids']\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]:,} samples x {X_train.shape[1]:,} features\")\n",
    "print(f\"Test: {X_test.shape[0]:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train.shape\n",
    "n_susceptible = np.sum(y_train == 0)\n",
    "n_resistant = np.sum(y_train == 1)\n",
    "imbalance_ratio = n_susceptible / n_resistant\n",
    "\n",
    "non_zero = np.count_nonzero(X_train)\n",
    "total_entries = n_samples * n_features\n",
    "sparsity = 100 * (1 - non_zero / total_entries)\n",
    "\n",
    "print(f\"Samples: {n_samples:,} , Features: {n_features:,}\")\n",
    "print(f\"Class distribution: {n_susceptible:,} susceptible ({100*n_susceptible/n_samples:.1f}%), {n_resistant:,} resistant ({100*n_resistant/n_samples:.1f}%)\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Matrix sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73049e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "class_labels = ['Susceptible', 'Resistant']\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "bars = plt.bar(class_labels, class_counts.values, color=['#3498db', '#e67e22'], alpha=0.5)\n",
    "plt.ylabel('Count', fontsize=9)\n",
    "plt.title('Class Distribution', fontsize=10)\n",
    "plt.grid(axis='y', alpha=0.2)\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, class_counts.values)):\n",
    "    percentage = 100 * count / len(y_train)\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20, \n",
    "             f'{count:,}\\n({percentage:.1f}%)', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68088f",
   "metadata": {},
   "source": [
    "### 1.2 Exploratory Data Analysis\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Class Imbalance (6.10:1 ratio)**\n",
    "   - 85.9% susceptible vs 14.1% resistant\n",
    "   - Solution: Balanced class weights in models\n",
    "\n",
    "2. **High Dimensionality**\n",
    "   - 1,000,000 features for 1,939 samples\n",
    "   - Risk: Overfitting without feature selection\n",
    "\n",
    "3. **Low Sparsity (1.60%)**\n",
    "   - 98.4% non-zero entries\n",
    "   - K-mers are common across samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FEATURES = 10000\n",
    "\n",
    "\n",
    "variance_threshold = VarianceThreshold(threshold=0.01)\n",
    "X_train_var = variance_threshold.fit_transform(X_train)\n",
    "X_test_var = variance_threshold.transform(X_test)\n",
    "\n",
    "\n",
    "selector = SelectKBest(chi2, k=min(K_FEATURES, X_train_var.shape[1]))\n",
    "X_train_selected = selector.fit_transform(X_train_var, y_train)\n",
    "X_test_selected = selector.transform(X_test_var)\n",
    "\n",
    "print(f\"Feature selection: {X_train.shape[1]:,} to {X_train_selected.shape[1]:,} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65eab6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Feature Selection\n",
    "\n",
    "Apply two-stage filtering to reduce from 1,000,000 to 10,000 features\n",
    "\n",
    "### 2.1 Feature Selection Strategy\n",
    "\n",
    "**Two-Stage Filtering Approach:**\n",
    "\n",
    "1. **Stage 1: Variance Threshold**\n",
    "   - Remove near-constant features (threshold = 0.01)\n",
    "   - Fast O(n) complexity\n",
    "   - Eliminates ~50% of features\n",
    "\n",
    "2. **Stage 2: Chi-Square Test**\n",
    "   - Statistical test for categorical data\n",
    "   - 10-100x faster than mutual information\n",
    "   - Selects top 10,000 discriminative features\n",
    "\n",
    "**Why This Works:**\n",
    "- K-mer counts are non-negative (ideal for chi-square)\n",
    "- Pipeline completes in ~60 seconds vs 10+ minutes\n",
    "- Maintains predictive power while reducing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = selector.scores_\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(feature_scores, bins=50, color='#9b59b6', alpha=0.5)\n",
    "axes[0].set_xlabel('Score', fontsize=9)\n",
    "axes[0].set_ylabel('Frequency', fontsize=9)\n",
    "axes[0].set_title('Feature Score Distribution', fontsize=10)\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(axis='y', alpha=0.2)\n",
    "\n",
    "top_scores = sorted(feature_scores, reverse=True)[:15]\n",
    "axes[1].barh(range(15), top_scores, color='#1abc9c', alpha=0.5)\n",
    "axes[1].set_xlabel('Score', fontsize=9)\n",
    "axes[1].set_ylabel('Rank', fontsize=9)\n",
    "axes[1].set_title('Top 15 Features', fontsize=10)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54de0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Validation\n",
    "\n",
    "Setup cross-validation strategy for robust model evaluation\n",
    "\n",
    "### 3.1 Validation Strategy\n",
    "\n",
    "**Stratified K-Fold Cross-Validation:**\n",
    "- 5 folds with stratification to maintain class distribution\n",
    "- Each fold tests on 20% of data, trains on 80%\n",
    "- Provides robust performance estimate\n",
    "\n",
    "**Why Stratified?**\n",
    "- Standard k-fold could create folds with very few resistant samples\n",
    "- Stratification ensures each fold has 14% resistant samples\n",
    "- Critical for imbalanced datasets\n",
    "\n",
    "**Macro F1-Score:**\n",
    "- Averages F1 for each class equally\n",
    "- Prevents bias toward majority class\n",
    "- Better metric than accuracy for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c00964",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Algorithms & Optimization\n",
    "\n",
    "Train and optimize classification models with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90a633",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_baseline = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42, n_jobs=-1)\n",
    "lr_scores = cross_val_score(lr_baseline, X_train_selected, y_train, cv=cv, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "print(f\"Logistic Regression Baseline: CV F1 = {lr_scores.mean():.4f}\")\n",
    "\n",
    "lr_baseline.fit(X_train_selected, y_train)\n",
    "baseline_score = lr_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31fd02",
   "metadata": {},
   "source": [
    "### 4.2 Grid Search Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [10, 15, 20, 25, None],\n",
    "    'min_samples_split': [5, 10, 15, 20],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "print(f\"Using 10-fold cross-validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ac883",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_params,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Best RF: F1 = {rf_grid.best_score_:.4f}, Params = {rf_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a496379",
   "metadata": {},
   "source": [
    "### 4.4 Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65aec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42, n_jobs=-1),\n",
    "    lr_params,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Best LR: F1 = {lr_grid.best_score_:.4f}, Params = {lr_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786720d",
   "metadata": {},
   "source": [
    "### 4.5 SVM Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f734e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(class_weight='balanced', random_state=42, cache_size=1000),\n",
    "    svm_params,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best SVM: F1 = {svm_grid.best_score_:.4f}, Params = {svm_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9582d",
   "metadata": {},
   "source": [
    "### 4.6 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = pd.DataFrame(rf_grid.cv_results_)\n",
    "lr_results = pd.DataFrame(lr_grid.cv_results_)\n",
    "svm_results = pd.DataFrame(svm_grid.cv_results_)\n",
    "\n",
    "rf_all = rf_results.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "lr_all = lr_results.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "svm_all = svm_results.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, row in rf_all.iterrows():\n",
    "    all_results.append({\n",
    "        'Model': 'RandomForest',\n",
    "        'Rank': int(row['rank_test_score']),\n",
    "        'CV_F1': row['mean_test_score'],\n",
    "        'CV_Std': row['std_test_score'],\n",
    "        'Config': str(row['params'])\n",
    "    })\n",
    "\n",
    "for idx, row in lr_all.iterrows():\n",
    "    all_results.append({\n",
    "        'Model': 'LogisticRegression',\n",
    "        'Rank': int(row['rank_test_score']),\n",
    "        'CV_F1': row['mean_test_score'],\n",
    "        'CV_Std': row['std_test_score'],\n",
    "        'Config': str(row['params'])\n",
    "    })\n",
    "\n",
    "for idx, row in svm_all.iterrows():\n",
    "    all_results.append({\n",
    "        'Model': 'SVM',\n",
    "        'Rank': int(row['rank_test_score']),\n",
    "        'CV_F1': row['mean_test_score'],\n",
    "        'CV_Std': row['std_test_score'],\n",
    "        'Config': str(row['params'])\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values('CV_F1', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Configurations:\")\n",
    "print(results_df.head(15).to_string(index=False))\n",
    "\n",
    "best = results_df.iloc[0]\n",
    "print(f\"\\nBest Model: {best['Model']} - CV F1 = {best['CV_F1']:.4f}\")\n",
    "\n",
    "results_df.to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e78b3a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Best Kaggle Submission\n",
    "\n",
    "Generate submission using best known Random Forest configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fe754",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_rf_scores = cross_val_score(best_rf, X_train_selected, y_train, cv=cv, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "print(f\"Best RF: CV F1 = {best_rf_scores.mean():.4f} (+/- {best_rf_scores.std():.4f})\")\n",
    "print(f\"Params: n_estimators=200, max_depth=20, min_samples_split=10\")\n",
    "\n",
    "best_rf.fit(X_train_selected, y_train)\n",
    "y_test_pred = best_rf.predict(X_test_selected)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred\n",
    "})\n",
    "\n",
    "submission_df.to_csv('best_submission.csv', index=False)\n",
    "print(f\"Predicted resistant: {np.sum(y_test_pred == 1)} ({100*np.sum(y_test_pred == 1)/len(y_test_pred):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec220571",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Grid Search Best Submission (TRAINING SET )\n",
    "\n",
    "Generate submission using best configuration from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_rf = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    max_depth=20,\n",
    "    min_samples_split=15,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_best_scores = cross_val_score(grid_best_rf, X_train_selected, y_train, cv=cv, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "print(f\"Grid Search Best RF: CV F1 = {grid_best_scores.mean():.4f}\")\n",
    "print(f\"Params: n_estimators=250, max_depth=20, min_samples_split=15\")\n",
    "\n",
    "grid_best_rf.fit(X_train_selected, y_train)\n",
    "y_test_pred_grid = grid_best_rf.predict(X_test_selected)\n",
    "\n",
    "submission_grid_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred_grid\n",
    "})\n",
    "\n",
    "submission_grid_df.to_csv('grid_search_best_submission.csv', index=False)\n",
    "print(f\"Predicted resistant: {np.sum(y_test_pred_grid == 1)} ({100*np.sum(y_test_pred_grid == 1)/len(y_test_pred_grid):.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
